{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Synthetic Tabular Data Generation Job\n",
        "\n",
        "This notebook generates synthetic tabular data using:\n",
        "- **dbldatagen** for structured data generation\n",
        "- **ai_query()** for GenAI Text columns\n",
        "- **Databricks volumes** for storage\n",
        "\n",
        "## Parameters\n",
        "The following parameters are passed from the app via job widgets:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Import required libraries\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr, col, lit\n",
        "from dbldatagen import DataGenerator, fakerText\n",
        "\n",
        "print(\"üì¶ Libraries imported successfully\")\n",
        "print(f\"   - Execution time: {datetime.now()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Get job parameters via widgets\n",
        "# Databricks automatically creates widgets from job parameters\n",
        "\n",
        "try:\n",
        "    # Create widgets with default values (these will be overridden by job parameters)\n",
        "    dbutils.widgets.text(\"table_name\", \"sample_table\", \"Table Name\")\n",
        "    dbutils.widgets.text(\"row_count\", \"1000\", \"Row Count\")\n",
        "    dbutils.widgets.text(\"columns\", \"[]\", \"Columns JSON\")\n",
        "    dbutils.widgets.text(\"company_name\", \"Sample Company\", \"Company Name\")\n",
        "    dbutils.widgets.text(\"company_sector\", \"Technology\", \"Company Sector\")\n",
        "    dbutils.widgets.text(\"timestamp\", datetime.now().strftime(\"%Y%m%d_%H%M%S\"), \"Timestamp\")\n",
        "    dbutils.widgets.text(\"endpoint_name\", \"databricks-gpt-oss-120b\", \"LLM Endpoint\")\n",
        "    dbutils.widgets.text(\"volume_path\", \"conor_smith.synthetic_data_app.synthetic_data_volume\", \"Volume Path\")\n",
        "    \n",
        "    # Get parameter values\n",
        "    table_name = dbutils.widgets.get(\"table_name\")\n",
        "    row_count = int(dbutils.widgets.get(\"row_count\"))\n",
        "    columns_json = dbutils.widgets.get(\"columns\")\n",
        "    company_name = dbutils.widgets.get(\"company_name\")\n",
        "    company_sector = dbutils.widgets.get(\"company_sector\")\n",
        "    timestamp = dbutils.widgets.get(\"timestamp\")\n",
        "    endpoint_name = dbutils.widgets.get(\"endpoint_name\")\n",
        "    volume_path = dbutils.widgets.get(\"volume_path\")\n",
        "    \n",
        "    print(\"üéØ Job Parameters Retrieved:\")\n",
        "    print(f\"   - Table name: {table_name}\")\n",
        "    print(f\"   - Row count: {row_count}\")\n",
        "    print(f\"   - Company: {company_name} ({company_sector})\")\n",
        "    print(f\"   - Timestamp: {timestamp}\")\n",
        "    print(f\"   - Endpoint: {endpoint_name}\")\n",
        "    print(f\"   - Volume: {volume_path}\")\n",
        "    print(f\"   - Columns JSON length: {len(columns_json)} characters\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error getting parameters: {e}\")\n",
        "    # Fallback to default values\n",
        "    table_name = \"sample_table\"\n",
        "    row_count = 1000\n",
        "    columns_json = \"[]\"\n",
        "    company_name = \"Sample Company\"\n",
        "    company_sector = \"Technology\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    endpoint_name = \"databricks-gpt-oss-120b\"\n",
        "    volume_path = \"conor_smith.synthetic_data_app.synthetic_data_volume\"\n",
        "    print(\"‚ö†Ô∏è  Using fallback default values\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Parse and validate column configurations\n",
        "try:\n",
        "    columns = json.loads(columns_json)\n",
        "    print(f\"‚úÖ Parsed {len(columns)} column configurations\")\n",
        "    \n",
        "    # Show column details\n",
        "    for i, col in enumerate(columns):\n",
        "        col_name = col.get('name', 'unnamed')\n",
        "        col_type = col.get('data_type', 'Unknown')\n",
        "        print(f\"   {i+1}. {col_name} ({col_type})\")\n",
        "        \n",
        "        # Show additional details for specific types\n",
        "        if col_type == 'Integer':\n",
        "            min_val = col.get('min_value', 'not set')\n",
        "            max_val = col.get('max_value', 'not set')\n",
        "            ordered = col.get('ordered_values', False)\n",
        "            print(f\"      ‚Üí Range: {min_val} to {max_val}\")\n",
        "            print(f\"      ‚Üí Ordered: {ordered}\")\n",
        "        elif col_type == 'Date':\n",
        "            min_date = col.get('min_date', 'not set')\n",
        "            max_date = col.get('max_date', 'not set')\n",
        "            ordered = col.get('ordered_values', False)\n",
        "            print(f\"      ‚Üí Date range: {min_date} to {max_date}\")\n",
        "            print(f\"      ‚Üí Ordered: {ordered}\")\n",
        "        elif col_type == 'GenAI Text':\n",
        "            prompt = col.get('prompt', 'not set')\n",
        "            max_tokens = col.get('max_tokens', 'not set')\n",
        "            print(f\"      ‚Üí Prompt: {prompt[:50]}{'...' if len(prompt) > 50 else ''}\")\n",
        "            print(f\"      ‚Üí Max tokens: {max_tokens}\")\n",
        "        elif col_type == 'Custom Values':\n",
        "            values = col.get('custom_values', [])\n",
        "            weights = col.get('use_weights', False)\n",
        "            ordered = col.get('ordered_values', False)\n",
        "            print(f\"      ‚Üí Values: {values[:3]}{'...' if len(values) > 3 else ''}\")\n",
        "            print(f\"      ‚Üí Weighted: {weights}\")\n",
        "            print(f\"      ‚Üí Ordered: {ordered}\")\n",
        "    \n",
        "    # Add sample columns if none provided\n",
        "    if len(columns) == 0:\n",
        "        print(\"‚ö†Ô∏è  No columns configured, adding sample columns for testing\")\n",
        "        columns = [\n",
        "            {\"name\": \"id\", \"data_type\": \"Integer\", \"min_value\": 1, \"max_value\": 1000, \"ordered_values\": False},\n",
        "            {\"name\": \"created_date\", \"data_type\": \"Date\", \"min_date\": \"2023-01-01\", \"max_date\": \"2024-12-31\", \"ordered_values\": False},\n",
        "            {\"name\": \"first_name\", \"data_type\": \"First Name\"},\n",
        "            {\"name\": \"last_name\", \"data_type\": \"Last Name\"},\n",
        "            {\"name\": \"bio\", \"data_type\": \"GenAI Text\", \"prompt\": \"Write a short professional bio for <first_name> <last_name>\", \"max_tokens\": 100}\n",
        "        ]\n",
        "        print(f\"   ‚Üí Added {len(columns)} sample columns\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error parsing columns: {e}\")\n",
        "    print(f\"   Raw columns_json: {columns_json}\")\n",
        "    # Use fallback columns\n",
        "    columns = [\n",
        "        {\"name\": \"id\", \"data_type\": \"Integer\", \"min_value\": 1, \"max_value\": 100, \"ordered_values\": False},\n",
        "        {\"name\": \"name\", \"data_type\": \"First Name\"}\n",
        "    ]\n",
        "    print(f\"   ‚Üí Using {len(columns)} fallback columns\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Initialize Spark and create DataGenerator\n",
        "try:\n",
        "    # Get Spark session\n",
        "    spark = SparkSession.getActiveSession()\n",
        "    if spark is None:\n",
        "        spark = SparkSession.builder.appName(\"TabularDataGeneration\").getOrCreate()\n",
        "    \n",
        "    print(\"‚ö° Spark session initialized\")\n",
        "    print(f\"   - Spark version: {spark.version}\")\n",
        "    \n",
        "    # Set partition parameters for optimal performance\n",
        "    partitions_requested = min(8, max(1, row_count // 1000))  \n",
        "    spark.conf.set(\"spark.sql.shuffle.partitions\", str(partitions_requested))\n",
        "    \n",
        "    print(f\"üîß Spark optimized for {row_count} rows ‚Üí {partitions_requested} partitions\")\n",
        "    \n",
        "    # Create DataGenerator\n",
        "    data_gen = DataGenerator(spark, rows=row_count, partitions=partitions_requested)\n",
        "    print(f\"üèóÔ∏è  DataGenerator created\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing Spark/DataGenerator: {e}\")\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Add columns to DataGenerator\n",
        "genai_columns = []\n",
        "\n",
        "for col_config in columns:\n",
        "    col_name = col_config.get('name', 'unnamed_column')\n",
        "    col_type = col_config.get('data_type', 'Integer')\n",
        "    \n",
        "    print(f\"üìä Adding column '{col_name}' ({col_type})\")\n",
        "    \n",
        "    try:\n",
        "        if col_type == 'Integer':\n",
        "            min_val = col_config.get('min_value', 1)\n",
        "            max_val = col_config.get('max_value', 100)\n",
        "            ordered_values = col_config.get('ordered_values', False)\n",
        "            random_vals = not ordered_values  # Use random=True unless ordered is explicitly True\n",
        "            data_gen = data_gen.withColumn(col_name, \"integer\", minValue=min_val, maxValue=max_val, random=random_vals)\n",
        "            print(f\"   ‚úÖ Integer: {min_val} to {max_val} (random={random_vals})\")\n",
        "            \n",
        "        elif col_type == 'Date':\n",
        "            min_date = col_config.get('min_date', '2020-01-01')\n",
        "            max_date = col_config.get('max_date', '2024-12-31')\n",
        "            ordered_values = col_config.get('ordered_values', False)\n",
        "            random_vals = not ordered_values  # Use random=True unless ordered is explicitly True\n",
        "            \n",
        "            try:\n",
        "                # Import DateRange from dbldatagen\n",
        "                import dbldatagen as dg\n",
        "                \n",
        "                # Validate date format and create proper datetime strings\n",
        "                from datetime import datetime\n",
        "                \n",
        "                # Parse and validate dates\n",
        "                try:\n",
        "                    min_dt = datetime.strptime(min_date, '%Y-%m-%d')\n",
        "                    max_dt = datetime.strptime(max_date, '%Y-%m-%d')\n",
        "                    print(f\"   - Parsed dates: {min_dt} to {max_dt}\")\n",
        "                except ValueError as date_error:\n",
        "                    print(f\"   ‚ö†Ô∏è  Invalid date format: {date_error}\")\n",
        "                    # Use default dates if parsing fails\n",
        "                    min_dt = datetime(2020, 1, 1)\n",
        "                    max_dt = datetime(2024, 12, 31)\n",
        "                    print(f\"   - Using default dates: {min_dt} to {max_dt}\")\n",
        "                \n",
        "                # Create date range with proper format for dbldatagen\n",
        "                min_date_str = min_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                max_date_str = max_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                \n",
        "                print(f\"   - Creating DateRange with: '{min_date_str}' to '{max_date_str}'\")\n",
        "                date_range = dg.DateRange(min_date_str, max_date_str)\n",
        "                print(f\"   - DateRange created successfully\")\n",
        "                \n",
        "                # Add column with date range\n",
        "                data_gen = data_gen.withColumn(col_name, \"date\", data_range=date_range, random=random_vals)\n",
        "                print(f\"   ‚úÖ Date: {min_date} to {max_date} (random={random_vals})\")\n",
        "                \n",
        "            except Exception as date_gen_error:\n",
        "                print(f\"   ‚ùå Error with DateRange generation: {date_gen_error}\")\n",
        "                print(f\"   üîÑ Falling back to timestamp generation...\")\n",
        "                try:\n",
        "                    # Fallback: Generate timestamps instead of dates\n",
        "                    data_gen = data_gen.withColumn(col_name, \"timestamp\", \n",
        "                                                 begin=\"2020-01-01 00:00:00\", \n",
        "                                                 end=\"2024-12-31 23:59:59\", \n",
        "                                                 interval=\"1 day\", random=random_vals)\n",
        "                    print(f\"   ‚úÖ Timestamp fallback: {min_date} to {max_date} (random={random_vals})\")\n",
        "                except Exception as fallback_error:\n",
        "                    print(f\"   ‚ùå Timestamp fallback also failed: {fallback_error}\")\n",
        "                    # Final fallback: generate as string\n",
        "                    data_gen = data_gen.withColumn(col_name, \"string\", values=[min_date])\n",
        "                    print(f\"   ‚ö†Ô∏è  Using string fallback with constant date: {min_date}\")\n",
        "            \n",
        "        elif col_type == 'First Name':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"first_name\"))\n",
        "                print(f\"   ‚úÖ First name with faker\")\n",
        "            except Exception:\n",
        "                first_names = [\"James\", \"Mary\", \"John\", \"Patricia\", \"Robert\", \"Jennifer\", \"Michael\", \"Linda\", \n",
        "                              \"William\", \"Elizabeth\", \"David\", \"Barbara\", \"Richard\", \"Susan\", \"Joseph\", \"Jessica\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=first_names)\n",
        "                print(f\"   ‚úÖ First name with predefined list ({len(first_names)} names)\")\n",
        "            \n",
        "        elif col_type == 'Last Name':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"last_name\"))\n",
        "                print(f\"   ‚úÖ Last name with faker\")\n",
        "            except Exception:\n",
        "                last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\",\n",
        "                             \"Rodriguez\", \"Martinez\", \"Hernandez\", \"Lopez\", \"Gonzalez\", \"Wilson\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=last_names)\n",
        "                print(f\"   ‚úÖ Last name with predefined list ({len(last_names)} names)\")\n",
        "        \n",
        "        elif col_type == 'Email':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"email\"))\n",
        "                print(f\"   ‚úÖ Email with faker\")\n",
        "            except Exception:\n",
        "                emails = [\"user@example.com\", \"test@domain.org\", \"sample@site.net\", \"admin@company.com\", \"contact@business.co\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=emails)\n",
        "                print(f\"   ‚úÖ Email with predefined list ({len(emails)} emails)\")\n",
        "        \n",
        "        elif col_type == 'Phone Number':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"phone_number\"))\n",
        "                print(f\"   ‚úÖ Phone number with faker\")\n",
        "            except Exception:\n",
        "                phones = [\"555-0100\", \"555-0101\", \"555-0102\", \"555-0103\", \"555-0104\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=phones)\n",
        "                print(f\"   ‚úÖ Phone number with predefined list ({len(phones)} numbers)\")\n",
        "        \n",
        "        elif col_type == 'Address':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"address\"))\n",
        "                print(f\"   ‚úÖ Address with faker\")\n",
        "            except Exception:\n",
        "                addresses = [\"123 Main St, New York, NY 10001\", \"456 Oak Ave, Los Angeles, CA 90210\", \n",
        "                           \"789 Pine Rd, Chicago, IL 60601\", \"321 Elm Dr, Houston, TX 77001\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=addresses)\n",
        "                print(f\"   ‚úÖ Address with predefined list ({len(addresses)} addresses)\")\n",
        "        \n",
        "        elif col_type == 'City':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"city\"))\n",
        "                print(f\"   ‚úÖ City with faker\")\n",
        "            except Exception:\n",
        "                cities = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Antonio\", \"San Diego\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=cities)\n",
        "                print(f\"   ‚úÖ City with predefined list ({len(cities)} cities)\")\n",
        "        \n",
        "        elif col_type == 'Country':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"country\"))\n",
        "                print(f\"   ‚úÖ Country with faker\")\n",
        "            except Exception:\n",
        "                countries = [\"United States\", \"Canada\", \"Mexico\", \"Brazil\", \"Argentina\", \"United Kingdom\", \"France\", \"Germany\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=countries)\n",
        "                print(f\"   ‚úÖ Country with predefined list ({len(countries)} countries)\")\n",
        "        \n",
        "        elif col_type == 'Country Code':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"country_code\"))\n",
        "                print(f\"   ‚úÖ Country code with faker\")\n",
        "            except Exception:\n",
        "                codes = [\"US\", \"CA\", \"MX\", \"BR\", \"AR\", \"GB\", \"FR\", \"DE\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=codes)\n",
        "                print(f\"   ‚úÖ Country code with predefined list ({len(codes)} codes)\")\n",
        "        \n",
        "        elif col_type == 'Postcode':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"postcode\"))\n",
        "                print(f\"   ‚úÖ Postcode with faker\")\n",
        "            except Exception:\n",
        "                postcodes = [\"10001\", \"90210\", \"60601\", \"77001\", \"85001\", \"19101\", \"78201\", \"92101\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=postcodes)\n",
        "                print(f\"   ‚úÖ Postcode with predefined list ({len(postcodes)} postcodes)\")\n",
        "        \n",
        "        elif col_type == 'Street Address':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"street_address\"))\n",
        "                print(f\"   ‚úÖ Street address with faker\")\n",
        "            except Exception:\n",
        "                streets = [\"123 Main St\", \"456 Oak Ave\", \"789 Pine Rd\", \"321 Elm Dr\", \"654 Cedar Ln\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=streets)\n",
        "                print(f\"   ‚úÖ Street address with predefined list ({len(streets)} addresses)\")\n",
        "        \n",
        "        elif col_type == 'Company':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"company\"))\n",
        "                print(f\"   ‚úÖ Company with faker\")\n",
        "            except Exception:\n",
        "                companies = [\"Acme Corp\", \"Global Industries\", \"Tech Solutions\", \"Data Systems\", \"Innovation Labs\", \"Future Enterprises\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=companies)\n",
        "                print(f\"   ‚úÖ Company with predefined list ({len(companies)} companies)\")\n",
        "        \n",
        "        elif col_type == 'Credit Card Number':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"credit_card_number\"))\n",
        "                print(f\"   ‚úÖ Credit card number with faker\")\n",
        "            except Exception:\n",
        "                # Using fake but valid test credit card numbers\n",
        "                cards = [\"4111-1111-1111-1111\", \"4000-0000-0000-0002\", \"5555-5555-5555-4444\", \"3782-822463-10005\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=cards)\n",
        "                print(f\"   ‚úÖ Credit card number with predefined list ({len(cards)} numbers)\")\n",
        "        \n",
        "        elif col_type == 'Credit Card Provider':\n",
        "            try:\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"credit_card_provider\"))\n",
        "                print(f\"   ‚úÖ Credit card provider with faker\")\n",
        "            except Exception:\n",
        "                providers = [\"Visa\", \"Mastercard\", \"American Express\", \"Discover\"]\n",
        "                data_gen = data_gen.withColumn(col_name, values=providers)\n",
        "                print(f\"   ‚úÖ Credit card provider with predefined list ({len(providers)} providers)\")\n",
        "        \n",
        "        elif col_type == 'Latitude':\n",
        "            try:\n",
        "                # For latitude, use fakerText which returns decimal values\n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"latitude\"))\n",
        "                print(f\"   ‚úÖ Latitude with faker (decimal values)\")\n",
        "            except Exception:\n",
        "                # Fallback to realistic latitude range (-90 to 90)\n",
        "                import random\n",
        "                latitudes = [round(random.uniform(-90.0, 90.0), 6) for _ in range(10)]\n",
        "                data_gen = data_gen.withColumn(col_name, values=latitudes)\n",
        "                print(f\"   ‚úÖ Latitude with predefined range ({len(latitudes)} values)\")\n",
        "        \n",
        "        elif col_type == 'Longitude':\n",
        "            try:\n",
        "                # For longitude, use fakerText which returns decimal values  \n",
        "                data_gen = data_gen.withColumn(col_name, text=fakerText(\"longitude\"))\n",
        "                print(f\"   ‚úÖ Longitude with faker (decimal values)\")\n",
        "            except Exception:\n",
        "                # Fallback to realistic longitude range (-180 to 180)\n",
        "                import random\n",
        "                longitudes = [round(random.uniform(-180.0, 180.0), 6) for _ in range(10)]\n",
        "                data_gen = data_gen.withColumn(col_name, values=longitudes)\n",
        "                print(f\"   ‚úÖ Longitude with predefined range ({len(longitudes)} values)\")\n",
        "            \n",
        "        elif col_type == 'GenAI Text':\n",
        "            # Add placeholder, will process with ai_query later\n",
        "            data_gen = data_gen.withColumn(col_name, \"string\", values=[\"\"])\n",
        "            genai_columns.append(col_config)\n",
        "            print(f\"   ‚úÖ GenAI placeholder (will use ai_query)\")\n",
        "            \n",
        "        elif col_type == 'Custom Values':\n",
        "            custom_values = col_config.get('custom_values', [''])\n",
        "            use_weights = col_config.get('use_weights', False)\n",
        "            custom_weights = col_config.get('custom_weights', [1])\n",
        "            ordered_values = col_config.get('ordered_values', False)\n",
        "            random_vals = not ordered_values  # Use random=True unless ordered is explicitly True\n",
        "            \n",
        "            filtered_values = [v for v in custom_values if v.strip()]\n",
        "            if not filtered_values:\n",
        "                filtered_values = ['DefaultValue']\n",
        "            \n",
        "            if use_weights and len(custom_weights) >= len(filtered_values):\n",
        "                filtered_weights = custom_weights[:len(filtered_values)]\n",
        "                data_gen = data_gen.withColumn(col_name, values=filtered_values, weights=filtered_weights, random=random_vals)\n",
        "                print(f\"   ‚úÖ Custom values with weights: {len(filtered_values)} values (random={random_vals})\")\n",
        "            else:\n",
        "                data_gen = data_gen.withColumn(col_name, values=filtered_values, random=random_vals)\n",
        "                print(f\"   ‚úÖ Custom values: {len(filtered_values)} values (random={random_vals})\")\n",
        "        \n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è  Unknown column type '{col_type}', skipping\")\n",
        "            \n",
        "    except Exception as col_error:\n",
        "        print(f\"   ‚ùå Error adding column '{col_name}': {col_error}\")\n",
        "\n",
        "print(f\"\\nüìã Summary: {len(columns)} total columns, {len(genai_columns)} GenAI columns\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Generate initial DataFrame and process GenAI columns\n",
        "# Build the initial DataFrame\n",
        "print(f\"üèóÔ∏è  Building DataFrame with {row_count} rows...\")\n",
        "df = data_gen.build()\n",
        "\n",
        "print(f\"‚úÖ DataFrame created: {df.count()} rows √ó {len(df.columns)} columns\")\n",
        "print(f\"   - Columns: {df.columns}\")\n",
        "\n",
        "# Show sample data\n",
        "print(f\"\\nüìä Sample Data (first 3 rows):\")\n",
        "df.show(3, truncate=False)\n",
        "\n",
        "# Process GenAI Text columns with ai_query\n",
        "if genai_columns:\n",
        "    print(f\"\\nü§ñ Processing {len(genai_columns)} GenAI Text columns with ai_query\")\n",
        "    \n",
        "    def substitute_column_references_spark(prompt_template, columns):\n",
        "        \"\"\"Create Spark SQL expression for column substitution.\"\"\"\n",
        "        import re\n",
        "        column_refs = re.findall(r'<([^<>]+)>', prompt_template)\n",
        "        \n",
        "        if not column_refs:\n",
        "            return f\"'{prompt_template}'\"\n",
        "        \n",
        "        # Build concat expression for dynamic prompt\n",
        "        parts = []\n",
        "        current_pos = 0\n",
        "        \n",
        "        for match in re.finditer(r'<([^<>]+)>', prompt_template):\n",
        "            col_name = match.group(1)\n",
        "            start_pos = match.start()\n",
        "            end_pos = match.end()\n",
        "            \n",
        "            # Add text before column reference\n",
        "            if start_pos > current_pos:\n",
        "                literal_text = prompt_template[current_pos:start_pos]\n",
        "                if literal_text:\n",
        "                    parts.append(f\"'{literal_text}'\")\n",
        "            \n",
        "            # Add column reference\n",
        "            valid_columns = [col.get('name', 'unnamed_column') for col in columns]\n",
        "            if col_name in valid_columns:\n",
        "                parts.append(f\"coalesce(cast({col_name} as string), 'NULL')\")\n",
        "            else:\n",
        "                parts.append(f\"'<{col_name}>'\")\n",
        "            \n",
        "            current_pos = end_pos\n",
        "        \n",
        "        # Add remaining text\n",
        "        if current_pos < len(prompt_template):\n",
        "            literal_text = prompt_template[current_pos:]\n",
        "            if literal_text:\n",
        "                parts.append(f\"'{literal_text}'\")\n",
        "        \n",
        "        return f\"concat({', '.join(parts)})\" if len(parts) > 1 else parts[0]\n",
        "    \n",
        "    # Process each GenAI column\n",
        "    for col_config in genai_columns:\n",
        "        col_name = col_config.get('name', 'unnamed_column')\n",
        "        prompt_template = col_config.get('prompt', '')\n",
        "        \n",
        "        if prompt_template:\n",
        "            print(f\"\\nüéØ Processing GenAI column '{col_name}'\")\n",
        "            print(f\"   - Prompt: {prompt_template[:80]}{'...' if len(prompt_template) > 80 else ''}\")\n",
        "            \n",
        "            try:\n",
        "                # Enhanced prompt for table context\n",
        "                enhanced_prompt = f\"{prompt_template} Note: This will be text data in a table so omit all special formatting.\"\n",
        "                \n",
        "                # Create dynamic prompt with column substitution\n",
        "                prompt_expression = substitute_column_references_spark(enhanced_prompt, columns)\n",
        "                print(f\"   - Spark expression created\")\n",
        "                \n",
        "                # Execute ai_query\n",
        "                print(f\"   - Executing ai_query with endpoint: {endpoint_name}\")\n",
        "                df = df.withColumn(\n",
        "                    col_name,\n",
        "                    expr(f\"ai_query(endpoint => '{endpoint_name}', request => {prompt_expression})\")\n",
        "                )\n",
        "                \n",
        "                print(f\"   ‚úÖ ai_query completed for '{col_name}'\")\n",
        "                \n",
        "                # Show sample generated text\n",
        "                sample_rows = df.select(col_name).limit(2).collect()\n",
        "                for i, row in enumerate(sample_rows):\n",
        "                    text_sample = str(row[col_name])[:100] + ('...' if len(str(row[col_name])) > 100 else '')\n",
        "                    print(f\"   - Sample {i+1}: {text_sample}\")\n",
        "                \n",
        "            except Exception as ai_error:\n",
        "                print(f\"   ‚ùå Error processing GenAI column '{col_name}': {ai_error}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ All GenAI columns processed\")\n",
        "else:\n",
        "    print(f\"\\n‚ÑπÔ∏è  No GenAI columns to process\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Save to Volume and complete job\n",
        "try:\n",
        "    filename = f\"{table_name}_{timestamp}.csv\"\n",
        "    print(f\"üíæ Saving data to volume...\")\n",
        "    print(f\"   - Filename: {filename}\")\n",
        "    print(f\"   - Volume parameter: {volume_path}\")\n",
        "    \n",
        "    # Convert to Pandas for clean CSV creation\n",
        "    print(f\"üìä Converting to Pandas...\")\n",
        "    pandas_df = df.toPandas()\n",
        "    print(f\"   ‚úÖ Pandas DataFrame: {len(pandas_df)} rows √ó {len(pandas_df.columns)} columns\")\n",
        "    \n",
        "    # Write to temporary location\n",
        "    temp_path = f\"/tmp/{filename}\"\n",
        "    pandas_df.to_csv(temp_path, index=False)\n",
        "    print(f\"   ‚úÖ Temporary file created: {temp_path}\")\n",
        "    \n",
        "    # Fix volume path format - convert dots to forward slashes for Unity Catalog\n",
        "    # Expected format: catalog.schema.volume ‚Üí /Volumes/catalog/schema/volume\n",
        "    if '.' in volume_path:\n",
        "        # Split volume_path and reconstruct proper Unity Catalog path\n",
        "        parts = volume_path.split('.')\n",
        "        if len(parts) >= 3:\n",
        "            catalog, schema, volume = parts[0], parts[1], parts[2]\n",
        "            corrected_volume_path = f\"/Volumes/{catalog}/{schema}/{volume}\"\n",
        "        else:\n",
        "            # Fallback if format is unexpected\n",
        "            corrected_volume_path = f\"/Volumes/{volume_path.replace('.', '/')}\"\n",
        "    else:\n",
        "        # Already in correct format or use as-is\n",
        "        corrected_volume_path = f\"/Volumes/{volume_path}\" if not volume_path.startswith('/Volumes/') else volume_path\n",
        "    \n",
        "    volume_file_path = f\"{corrected_volume_path}/{filename}\"\n",
        "    print(f\"üì§ Corrected volume path: {corrected_volume_path}\")\n",
        "    print(f\"üì§ Full file path: {volume_file_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Ensure volume directory exists\n",
        "        print(f\"üìÅ Ensuring volume directory exists...\")\n",
        "        dbutils.fs.mkdirs(corrected_volume_path)\n",
        "        \n",
        "        # Copy file to volume\n",
        "        dbutils.fs.cp(f\"file://{temp_path}\", volume_file_path)\n",
        "        print(f\"   ‚úÖ Successfully saved to volume!\")\n",
        "        \n",
        "        # Verify file\n",
        "        try:\n",
        "            file_info = dbutils.fs.ls(volume_file_path)\n",
        "            file_size = file_info[0].size if file_info else 0\n",
        "            print(f\"   üìã File size: {file_size:,} bytes\")\n",
        "        except:\n",
        "            print(f\"   ‚ö†Ô∏è  Could not verify file size\")\n",
        "        \n",
        "        # Clean up temp file\n",
        "        dbutils.fs.rm(f\"file://{temp_path}\")\n",
        "        print(f\"   üßπ Cleaned up temporary file\")\n",
        "        \n",
        "    except Exception as volume_error:\n",
        "        print(f\"   ‚ùå Error copying to volume: {volume_error}\")\n",
        "        print(f\"   üìÅ File remains at: {temp_path}\")\n",
        "        volume_file_path = temp_path\n",
        "    \n",
        "    # Final summary\n",
        "    print(f\"\\nüéâ Job Completed Successfully!\")\n",
        "    print(f\"üìã Final Summary:\")\n",
        "    print(f\"   - Table: {table_name}\")\n",
        "    print(f\"   - Rows: {df.count():,}\")\n",
        "    print(f\"   - Columns: {len(df.columns)}\")\n",
        "    print(f\"   - GenAI columns: {len(genai_columns)}\")\n",
        "    print(f\"   - Company: {company_name} ({company_sector})\")\n",
        "    print(f\"   - File: {volume_file_path}\")\n",
        "    print(f\"   - Completed: {datetime.now()}\")\n",
        "    \n",
        "    # Show final sample\n",
        "    print(f\"\\nüìä Final Data Sample:\")\n",
        "    df.show(5, truncate=False)\n",
        "    \n",
        "except Exception as save_error:\n",
        "    print(f\"‚ùå Error during save: {save_error}\")\n",
        "    print(f\"   Job may have succeeded but file save failed\")\n",
        "    raise save_error\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
